<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang='en'>
	<head>
		<title>Testing installation instructions - Rants from the Ballmer Peak</title>
		<meta name="viewport" content="initial-scale=1, maximum-scale=1">
		<link rel="stylesheet" href="../../../css/normalize.css">
		<link rel="stylesheet" href="../../../css/style.css">
		<link href="../../../feed.xml" title="Articles" type="application/atom+xml" rel="alternate">
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	</head>
	<body>
	<div class="content">
		<h3><a href="../../../index.html">Rants from the Ballmer Peak</a> <a
				href="../../../feed.xml"><img
			alt="rss feed" src="../../../i/Feed-icon.svg"
			width="18pt" height="18pt"></a></h3>
		<h1>Testing installation instructions</h1><p>Unit testing seems like the most recent and popular <a href="http://www.urbandictionary.com/define.php?term=e-penis">e-penis</a> game in the industry: not only can you brag about useless stuff in big numbers (<span style="font-style: italic;">look, we have more than thousand unit tests for stuff nobody uses!</span>), but you can push this data to upper management and they will pat you on your back for it. Not because they find that unit testing is useful for software, promotes sane development approaches, documents working code and corner cases/bugs, or in general requires some interest in output from code monkeys.  No, they like unit testing because it can be represented as a number associated with specific developers, and the human resources department can compare these numbers over time to increase salaries. <a href="http://stackoverflow.com/questions/3769716/how-bad-is-sloc-source-lines-of-code-as-a-metric">It's lines of code all over again, and everybody loves it</a>.</p>
<p>Except for very specific kinds of software, unit testing is likely not very useful to end users. In fact, when you test something <span style="font-weight: bold;">which matters</span> to end users, it stops being called unit testing, and it is called <a href="https://en.wikipedia.org/wiki/Integration_testing">integration testing</a> or <a href="https://en.wikipedia.org/wiki/Verification_and_validation_(software)">validation testing</a>. This is serious crap. Like keeping virtual machines which simulate the <span style="font-weight: bold;">first installation</span> by the user on an otherwise clean state OS (so you know if that 3rd party library you recently added requires an additional DLL install). Or if your software doesn't run in a virtual machine, keeping the hardware machines (with spares) to keep testing newer versions. These kinds of testing tend to take days compared to minutes in the software development.</p>
<p>Unfortunately they are a pain in the ass to set up, so even important projects don't care about them and depend on beta testâ€¦ er, users, to tell them something has gone wrong. One critical point of many open source projects which goes untested is: installation instructions. You know, the little sequence of commands which tells you what to do to actually get the source code, build it, and maybe install it. Either in binary or source form, installation instructions are the first step for your users and other potential developers to know about you. Bad installation instructions are the equivalent of a web page which never loads: users will look elsewhere. Yet they are not that difficult to test. In fact, everybody should be testing them.</p>
<h2>Testing dropbox_filename_sanitizer</h2><p>For this article I'll be using my own <a href="https://github.com/gradha/dropbox_filename_sanitizer">dropbox_filename_sanitizer project</a> because pointing errors in other people's software is too easy and doesn't enrich me. This project also offers a nice range of things to test: there is a stable source code installation, a development source code installation, and a pre built binary installation. In addition the program is implemented with the <a href="http://nim-lang.org">Nim programming language</a> which <a href="http://nim-lang.org/news.html#Z2014-04-21-version-0-9-4-released">recently released version 0.9.4</a>. A programming language in development may well render the source code useless between versions, so we will have to expand the source code tests to cover one using the stable compiler release and another using the unstable one. If my math is not wrong, that's more than a single test, enough to impress your mom.</p>
<p>The platforms to test are MacOSX and Linux. You can test Windows too, you can do nice things with <a href="https://oracleexamples.wordpress.com/2011/08/12/virtualbox-script-to-control-virtual-machines/">VirtualBox alone</a> or <a href="http://www.vagrantup.com/blog/feature-preview-vagrant-1-6-windows.html">with additional tools like Vagrant</a>, but I don't own any Windows licenses and have little interest in getting one. Since both target platforms are Unix-like, we will be able to reuse the scripting for both using <a href="https://www.gnu.org/software/bash/">bash</a> or whatever shell used by the systems used to run the test cases (if you don't control the environment, like on virtual host). We won't go the full virtual machine route because it is time expensive, and also because we can easily emulate nearly clean state environments through additional users.</p>

<img
    src="../../../i/nuke_orbit.jpg"
    alt="The only sane approach to software testing"
    style="width:100%;max-width:600px" align="right"
    hspace="8pt" vspace="8pt"><p>The strategy then is to create a separate user for testing in your own machine. This user won't have any of the installed dependencies required for installation, and we will install everything in specific directories which can later be erased to prevent them from polluting future tests. If the software you are using requires installation in global paths, you need a virtual machine then anyway. Certainly you don't <span style="font-style: italic;">trust</span> software to have a good uninstallation mechanism, do you?</p>
<p>A separate user account on the machine is easier to nuke from orbit should anything go wrong, but it also helps to keep yourself honest about the testing environment. If you run the tests as your development user many little environment changes can creep in and alter the tests. First we will write some code which will gather necessary runtime variables from the development environment or from json files producing a bash script. Then we copy the bash script to the user through a <a href="https://en.wikipedia.org/wiki/Secure_Shell">secure shell</a> and run it remotely.</p>
<p>The secure shell abstraction forces us to make a script which works remotely, can be run at any time, and we can run one instance in our development machine (MacOSX) and another one on a virtual box or hosted server (Linux). Secure shells are also easier to set up with public/private keys to avoid interactive prompts during testing. Of course you can set up passwords into the test scripts, but you have to be careful about <a href="https://stewilliams.com/silly-gits-upload-private-crypto-keys-to-public-github-projects/">private secrets not leaking to public repositories</a>. Making sure the user ssh setup is <span style="font-weight: bold;">not</span> part of your software repository can sometimes be a good thing.</p>
<h2>Testing the stable babel installation</h2><p>To install the stable version of dropbox_filename_sanitizer the user only has to type the following commands:<pre class='literal'>
$ babel update
$ babel install argument_parser
$ babel install dropbox_filename_sanitizer</pre></p>
<p>Fun fact: presumably you don't have to install <a href="https://github.com/gradha/argument_parser">argument_parser</a> manually since <a href="https://github.com/nimrod-code/babel">babel</a> will take care of dependencies. Unfortunately <a href="https://github.com/nimrod-code/babel/issues/37">a bug prevents correct installation</a> due to a mistake in handling version numbers. Yes, the problem was found while <a href="https://github.com/gradha/dropbox_filename_sanitizer/issues/12">setting up the project for testing</a> in advance for this blog post. Bug inception!</p>
<p>Since the project already features a <a href="https://github.com/gradha/dropbox_filename_sanitizer/blob/master/nakefile.nim">nakefile</a> which drives other tasks (see the <a href="https://github.com/fowlmouth/nake">nake project</a>) I decided to add a <a href="https://github.com/gradha/dropbox_filename_sanitizer/blob/329d5e7a52e5b4a705f89a68a751ce698e941501/nakefile.nim#L372">shell_test</a> command. This command accepts <a href="https://github.com/gradha/dropbox_filename_sanitizer/tree/329d5e7a52e5b4a705f89a68a751ce698e941501/shell_tests">json files</a> which contain some parameters of what is to be tested. Let's see <a href="https://github.com/gradha/dropbox_filename_sanitizer/blob/329d5e7a52e5b4a705f89a68a751ce698e941501/shell_tests/macosx_igor_nimrod_devel_chunk1.json">one of those json files first</a>:</p>
<ul><li><code>host</code>, <code>user</code>: These are the typical host and user parameters for the secure shell. Use <code>localhost</code> and a different user on your own machine to simulate a clean install.</li><li><code>nimrod_branch</code>: Specifies which branch to check out for the Nim compiler. You can specify tags as well for previous releases. In this case, we use the development branch.</li><li><code>nimrod_version_str</code>: The string we will use with <a href="https://www.gnu.org/software/grep/">grep</a> in the script to verify that the compiler we invoke is the proper one. Since this is the development version, we don't care about the version, but stable version checking will feature a specific number (like 0.9.4).</li><li><code>nimrod_csources_branch</code>: Similar to <code>nimrod_branch</code>, this is the branch used by the sub repository csources required by the compiler.</li><li><code>chunk_file</code>: Name of the documentation file we will extract installation steps performed by the user.</li><li><code>chunk_number</code>: Index of the instructions <span style="font-style: italic;">block</span> that we are testing. The readme features several possible instructions, having different json files for each block.</li><li><code>bin_version</code>: Similar to <code>nimrod_version_str</code>, this parameter specifies if we are testing against the development version of dropbox_filename_sanitizer (which will get the number directly imported from the module) or the last stable version (which will be obtained from git tags).</li></ul><p>The nakefile code for the task is a little bit split and tough to follow sequentially, so I've put at <a href="https://gist.github.com/gradha/aff3c6d53657a27e4cae">https://gist.github.com/gradha/aff3c6d53657a27e4cae</a> an example of generated shell script. This is the shell script that is copied to the remote user and run as is. The only dependency required is a working compiler. The script first sets up some variables to reuse, removes previous temporary files which could have been left from failure runs, and starts to install both the Nim compiler and babel. Quite boring, but necessary.</p>
<p>By the very end of the script, <a href="https://gist.github.com/gradha/aff3c6d53657a27e4cae#file-shell_test_1398956253-sh-L58">on line 58</a> you will recognise the three commands mentioned above to update babel, install argument_parser, then install the program. <a href="https://gist.github.com/gradha/aff3c6d53657a27e4cae#file-shell_test_1398956253-sh-L54">Previously line 54</a> did export the private babel binary directory (<code>.babel/bin</code>) to test a normal user invoking the binary without typing the full path to it. This can be seen in the <a href="https://gist.github.com/gradha/aff3c6d53657a27e4cae#file-shell_test_1398956253-sh-L62">last test line 62</a> which verifies the installed version of the command running the command's <code>--version</code> switch piped to <a href="https://www.gnu.org/software/grep/">grep</a>. If <code>grep</code> doesn't find a match it will return an error, which will abort the whole script, courtesy of <a href="https://gist.github.com/gradha/aff3c6d53657a27e4cae#file-shell_test_1398956253-sh-L4">line 4 forcing immediate exit</a> if any of the following commands returns a non zero error status.</p>
<h2>Testing the development babel installation</h2><p>To install the development version of dropbox_filename_sanitizer the user has to type a little bit more:<pre class='literal'>
$ babel update
$ babel install argument_parser
$ git clone https://github.com/gradha/dropbox_filename_sanitizer.git
$ cd dropbox_filename_sanitizer
$ babel install</pre></p>
<p>The only difference is that instead of asking babel to fetch the package we clone the git repository and install it manually by omitting the parameter (and having a <a href="https://github.com/gradha/dropbox_filename_sanitizer/blob/master/dropbox_filename_sanitizer.babel">babel spec file available</a> in the working directory). The only difference between the stable and development versions of the test script will be the lines run to install the software. These lines are obtained through the previously mentioned <code>chunk_number</code> parameter in the json file.  The crude <a href="https://github.com/gradha/dropbox_filename_sanitizer/blob/329d5e7a52e5b4a705f89a68a751ce698e941501/nakefile.nim#L252">gen_chunk_script</a> proc in the nakefile will parse the readme and extract all the lines for whatever block was specified. One could go hi-tech and use the <a href="http://nim-lang.org/rst_module.html">rst nim module</a> to parse the readme, but simple line stripping serves well.</p>
<h2>Testing the pre built binaries</h2><p>I haven't bothered yet to do this for a very simple reason: you only need to test this once. The compiled binaries work without dependencies, so by the time you create them, you test them yourself once andâ€¦ that's it! It's the source installation which depends on many more steps and packages which can go wrong. Certainly there is room to test for <a href="https://github.com/gradha/dropbox_filename_sanitizer/issues/11">failures in the packaging itself</a>, but the packaging itself is automated. Maybe if I get very bored I'll do it.</p>
<h2>Conclusion</h2>
<img
    src="../../../i/so_metal.jpg"
    alt="Tiffany approves"
    style="width:100%;max-width:750px" align="right"
    hspace="8pt" vspace="8pt"><p>It takes some time to set these kind of tests, but they are critical: if potential users of your software find that they can't even install it, they won't bother to contact you to fix it, you require a lot of interest for that to happen. So you better know first that something is broken. The huge amount of github projects which don't even compile without tweaking is sad (or maybe I'm just unlucky?).</p>
<p>As a bonus you know when things go wrong without others having to tell you. Since these integration tests also test external software, you are sort of contributing to the <a href="http://forum.nim-lang.org">Nim community</a> by testing the compiler (both the last stable and last development versions) and the approved package manager used by many others.</p>
<p>I've wondered if these tests should go the route of continuous integration. That seems to be a lot of work but possible through <a href="https://developer.github.com/v3/repos/hooks/">GitHub webhooks</a>. On the other hand maybe webhooks don't work for watching external repositories you don't have control over. Since installation instructions are not going to change from day to day, it would be also possible to write a polling script which every night checks the current Nim compiler version, and if changed, runs the tests.  Changing from continuous integration to nightly builds is not that bad either and still provides a reasonably fast response to external changes if something goes wrong.</p>
<p>If you develop a Nim based pseudo continuous software tester, let me know!</p>

<br clear="right"><pre class='literal'>$ unzip dropbox_filename_sanitizer-0.4.0-macosx.zip
Archive:  dropbox_filename_sanitizer-0.4.0-macosx.zip
  inflating: dropbox_filename_sanitizer
  inflating: readme.html
  â€¦
$ ./dropbox_filename_sanitizer
-bash: ./dropbox_filename_sanitizer: Permission denied
</pre>
	</div>
		<hr>
		<p>See <a href="../../../index.html">the article index</a> or browse
		articles by tags:     <a href="../../../tags/nim.html">nim</a>
    ,
    <a href="../../../tags/nimrod.html">nimrod</a>
    ,
    <a href="../../../tags/testing.html">testing</a>
    ,
    <a href="../../../tags/programming.html">programming</a>
    ,
    <a href="../../../tags/user-experience.html">user experience</a>
    
.<br>Published on: 01/05/2014 17:00. Last update:
			01/05/2014 17:34. <a
			href="../../../feed.xml"><img
			alt="rss feed" src="../../../i/Feed-icon.svg"
			width="18pt" height="18pt"></a><br>
		Copyright 2014 by <a href="../../../about.html">Grzegorz Adam Hankiewicz</a>.<br>
		Generated with <a href="https://github.com/dom96/ipsumgenera">ipsum
			genera</a>. Look at <a
		href="https://github.com/gradha/gradha.github.io">the
		source code</a>. Or look at <a href="../../../cookie-policy.html">my
	cookie policy which you implicitly accept</a>.</p>
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48814780-1', 'gradha.github.io');
  ga('send', 'pageview');

</script>
	</body>
</html>
